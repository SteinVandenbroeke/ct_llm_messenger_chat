{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.1000028377649763,
  "eval_steps": 500,
  "global_step": 1762,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0005675529952609325,
      "grad_norm": 44.60840606689453,
      "learning_rate": 0.00019954597048808172,
      "loss": 12.2515,
      "step": 10
    },
    {
      "epoch": 0.001135105990521865,
      "grad_norm": 74.35138702392578,
      "learning_rate": 0.00019852440408626561,
      "loss": 4.3724,
      "step": 20
    },
    {
      "epoch": 0.0017026589857827975,
      "grad_norm": 0.6944983601570129,
      "learning_rate": 0.00019738933030646994,
      "loss": 0.9958,
      "step": 30
    },
    {
      "epoch": 0.00227021198104373,
      "grad_norm": 0.5397242307662964,
      "learning_rate": 0.00019625425652667423,
      "loss": 0.7594,
      "step": 40
    },
    {
      "epoch": 0.0028377649763046625,
      "grad_norm": 0.5063507556915283,
      "learning_rate": 0.00019511918274687856,
      "loss": 0.6017,
      "step": 50
    },
    {
      "epoch": 0.003405317971565595,
      "grad_norm": 0.5454131364822388,
      "learning_rate": 0.00019398410896708288,
      "loss": 0.4724,
      "step": 60
    },
    {
      "epoch": 0.0039728709668265276,
      "grad_norm": 0.6767796277999878,
      "learning_rate": 0.00019284903518728718,
      "loss": 0.5037,
      "step": 70
    },
    {
      "epoch": 0.00454042396208746,
      "grad_norm": 0.8325806856155396,
      "learning_rate": 0.0001917139614074915,
      "loss": 0.5203,
      "step": 80
    },
    {
      "epoch": 0.005107976957348393,
      "grad_norm": 0.5608580112457275,
      "learning_rate": 0.0001905788876276958,
      "loss": 0.4249,
      "step": 90
    },
    {
      "epoch": 0.005675529952609325,
      "grad_norm": 0.6560145020484924,
      "learning_rate": 0.00018944381384790012,
      "loss": 0.4778,
      "step": 100
    },
    {
      "epoch": 0.006243082947870258,
      "grad_norm": 0.5202356576919556,
      "learning_rate": 0.00018830874006810444,
      "loss": 0.3806,
      "step": 110
    },
    {
      "epoch": 0.00681063594313119,
      "grad_norm": 0.47930800914764404,
      "learning_rate": 0.00018717366628830874,
      "loss": 0.5226,
      "step": 120
    },
    {
      "epoch": 0.007378188938392123,
      "grad_norm": 0.5442691445350647,
      "learning_rate": 0.00018603859250851306,
      "loss": 0.4325,
      "step": 130
    },
    {
      "epoch": 0.007945741933653055,
      "grad_norm": 0.6094608902931213,
      "learning_rate": 0.00018490351872871738,
      "loss": 0.4705,
      "step": 140
    },
    {
      "epoch": 0.008513294928913987,
      "grad_norm": 0.4088808596134186,
      "learning_rate": 0.00018376844494892168,
      "loss": 0.3702,
      "step": 150
    },
    {
      "epoch": 0.00908084792417492,
      "grad_norm": 0.44003772735595703,
      "learning_rate": 0.000182633371169126,
      "loss": 0.4088,
      "step": 160
    },
    {
      "epoch": 0.009648400919435852,
      "grad_norm": 0.42523717880249023,
      "learning_rate": 0.0001814982973893303,
      "loss": 0.3952,
      "step": 170
    },
    {
      "epoch": 0.010215953914696785,
      "grad_norm": 0.728143572807312,
      "learning_rate": 0.00018036322360953465,
      "loss": 0.4541,
      "step": 180
    },
    {
      "epoch": 0.010783506909957717,
      "grad_norm": 0.44706249237060547,
      "learning_rate": 0.00017922814982973895,
      "loss": 0.3702,
      "step": 190
    },
    {
      "epoch": 0.01135105990521865,
      "grad_norm": 0.3753456771373749,
      "learning_rate": 0.00017809307604994324,
      "loss": 0.3584,
      "step": 200
    },
    {
      "epoch": 0.011918612900479582,
      "grad_norm": 0.4117191433906555,
      "learning_rate": 0.00017695800227014757,
      "loss": 0.4485,
      "step": 210
    },
    {
      "epoch": 0.012486165895740515,
      "grad_norm": 0.7419931292533875,
      "learning_rate": 0.0001758229284903519,
      "loss": 0.5477,
      "step": 220
    },
    {
      "epoch": 0.013053718891001447,
      "grad_norm": 0.37590667605400085,
      "learning_rate": 0.00017468785471055619,
      "loss": 0.4683,
      "step": 230
    },
    {
      "epoch": 0.01362127188626238,
      "grad_norm": 0.426973432302475,
      "learning_rate": 0.0001735527809307605,
      "loss": 0.3947,
      "step": 240
    },
    {
      "epoch": 0.014188824881523312,
      "grad_norm": 0.5743309259414673,
      "learning_rate": 0.0001724177071509648,
      "loss": 0.3746,
      "step": 250
    },
    {
      "epoch": 0.014756377876784245,
      "grad_norm": 0.40511712431907654,
      "learning_rate": 0.00017128263337116916,
      "loss": 0.3895,
      "step": 260
    },
    {
      "epoch": 0.015323930872045177,
      "grad_norm": 0.6233329176902771,
      "learning_rate": 0.00017014755959137345,
      "loss": 0.359,
      "step": 270
    },
    {
      "epoch": 0.01589148386730611,
      "grad_norm": 0.4705647826194763,
      "learning_rate": 0.00016901248581157775,
      "loss": 0.4258,
      "step": 280
    },
    {
      "epoch": 0.016459036862567042,
      "grad_norm": 0.497435063123703,
      "learning_rate": 0.00016787741203178207,
      "loss": 0.3854,
      "step": 290
    },
    {
      "epoch": 0.017026589857827974,
      "grad_norm": 0.574981689453125,
      "learning_rate": 0.0001667423382519864,
      "loss": 0.3359,
      "step": 300
    },
    {
      "epoch": 0.01759414285308891,
      "grad_norm": 0.36093220114707947,
      "learning_rate": 0.0001656072644721907,
      "loss": 0.4408,
      "step": 310
    },
    {
      "epoch": 0.01816169584834984,
      "grad_norm": 0.48400142788887024,
      "learning_rate": 0.00016447219069239501,
      "loss": 0.3968,
      "step": 320
    },
    {
      "epoch": 0.018729248843610772,
      "grad_norm": 0.4012930393218994,
      "learning_rate": 0.0001633371169125993,
      "loss": 0.3638,
      "step": 330
    },
    {
      "epoch": 0.019296801838871704,
      "grad_norm": 0.3736041188240051,
      "learning_rate": 0.00016220204313280366,
      "loss": 0.3782,
      "step": 340
    },
    {
      "epoch": 0.01986435483413264,
      "grad_norm": 0.4362429678440094,
      "learning_rate": 0.00016106696935300796,
      "loss": 0.4041,
      "step": 350
    },
    {
      "epoch": 0.02043190782939357,
      "grad_norm": 0.35039040446281433,
      "learning_rate": 0.00015993189557321225,
      "loss": 0.4206,
      "step": 360
    },
    {
      "epoch": 0.020999460824654502,
      "grad_norm": 0.3821263611316681,
      "learning_rate": 0.00015879682179341658,
      "loss": 0.3238,
      "step": 370
    },
    {
      "epoch": 0.021567013819915434,
      "grad_norm": 0.3761266767978668,
      "learning_rate": 0.0001576617480136209,
      "loss": 0.4177,
      "step": 380
    },
    {
      "epoch": 0.02213456681517637,
      "grad_norm": 0.3843689560890198,
      "learning_rate": 0.00015652667423382522,
      "loss": 0.3792,
      "step": 390
    },
    {
      "epoch": 0.0227021198104373,
      "grad_norm": 0.32105666399002075,
      "learning_rate": 0.00015539160045402952,
      "loss": 0.3651,
      "step": 400
    },
    {
      "epoch": 0.023269672805698232,
      "grad_norm": 0.28413817286491394,
      "learning_rate": 0.00015425652667423382,
      "loss": 0.3902,
      "step": 410
    },
    {
      "epoch": 0.023837225800959164,
      "grad_norm": 0.43219059705734253,
      "learning_rate": 0.00015312145289443817,
      "loss": 0.4403,
      "step": 420
    },
    {
      "epoch": 0.0244047787962201,
      "grad_norm": 0.46818146109580994,
      "learning_rate": 0.00015198637911464246,
      "loss": 0.3666,
      "step": 430
    },
    {
      "epoch": 0.02497233179148103,
      "grad_norm": 0.3587196171283722,
      "learning_rate": 0.00015085130533484676,
      "loss": 0.3729,
      "step": 440
    },
    {
      "epoch": 0.025539884786741962,
      "grad_norm": 0.4226791560649872,
      "learning_rate": 0.00014971623155505108,
      "loss": 0.3993,
      "step": 450
    },
    {
      "epoch": 0.026107437782002894,
      "grad_norm": 0.3228309750556946,
      "learning_rate": 0.0001485811577752554,
      "loss": 0.3477,
      "step": 460
    },
    {
      "epoch": 0.026674990777263825,
      "grad_norm": 0.32737183570861816,
      "learning_rate": 0.00014744608399545973,
      "loss": 0.4305,
      "step": 470
    },
    {
      "epoch": 0.02724254377252476,
      "grad_norm": 0.349369615316391,
      "learning_rate": 0.00014631101021566402,
      "loss": 0.2965,
      "step": 480
    },
    {
      "epoch": 0.027810096767785692,
      "grad_norm": 0.42592352628707886,
      "learning_rate": 0.00014517593643586832,
      "loss": 0.3863,
      "step": 490
    },
    {
      "epoch": 0.028377649763046624,
      "grad_norm": 0.4054548740386963,
      "learning_rate": 0.00014404086265607267,
      "loss": 0.3351,
      "step": 500
    },
    {
      "epoch": 0.028945202758307555,
      "grad_norm": 0.34046584367752075,
      "learning_rate": 0.00014290578887627697,
      "loss": 0.3034,
      "step": 510
    },
    {
      "epoch": 0.02951275575356849,
      "grad_norm": 0.3450043797492981,
      "learning_rate": 0.0001417707150964813,
      "loss": 0.2944,
      "step": 520
    },
    {
      "epoch": 0.030080308748829422,
      "grad_norm": 0.545272946357727,
      "learning_rate": 0.00014063564131668559,
      "loss": 0.4849,
      "step": 530
    },
    {
      "epoch": 0.030647861744090354,
      "grad_norm": 0.47711607813835144,
      "learning_rate": 0.0001395005675368899,
      "loss": 0.3033,
      "step": 540
    },
    {
      "epoch": 0.031215414739351285,
      "grad_norm": 0.4809841811656952,
      "learning_rate": 0.00013836549375709423,
      "loss": 0.4271,
      "step": 550
    },
    {
      "epoch": 0.03178296773461222,
      "grad_norm": 0.3875170052051544,
      "learning_rate": 0.00013723041997729853,
      "loss": 0.3704,
      "step": 560
    },
    {
      "epoch": 0.03235052072987315,
      "grad_norm": 0.3999708294868469,
      "learning_rate": 0.00013609534619750283,
      "loss": 0.31,
      "step": 570
    },
    {
      "epoch": 0.032918073725134084,
      "grad_norm": 0.40860632061958313,
      "learning_rate": 0.00013496027241770718,
      "loss": 0.3871,
      "step": 580
    },
    {
      "epoch": 0.03348562672039502,
      "grad_norm": 0.4875541627407074,
      "learning_rate": 0.00013382519863791147,
      "loss": 0.3342,
      "step": 590
    },
    {
      "epoch": 0.03405317971565595,
      "grad_norm": 0.39641621708869934,
      "learning_rate": 0.0001326901248581158,
      "loss": 0.3406,
      "step": 600
    },
    {
      "epoch": 0.03462073271091688,
      "grad_norm": 0.3546830713748932,
      "learning_rate": 0.0001315550510783201,
      "loss": 0.3433,
      "step": 610
    },
    {
      "epoch": 0.03518828570617782,
      "grad_norm": 0.40633824467658997,
      "learning_rate": 0.00013041997729852441,
      "loss": 0.4089,
      "step": 620
    },
    {
      "epoch": 0.035755838701438745,
      "grad_norm": 0.6869888305664062,
      "learning_rate": 0.00012928490351872874,
      "loss": 0.3802,
      "step": 630
    },
    {
      "epoch": 0.03632339169669968,
      "grad_norm": 0.39869973063468933,
      "learning_rate": 0.00012814982973893303,
      "loss": 0.4665,
      "step": 640
    },
    {
      "epoch": 0.03689094469196061,
      "grad_norm": 0.4033600091934204,
      "learning_rate": 0.00012701475595913736,
      "loss": 0.3446,
      "step": 650
    },
    {
      "epoch": 0.037458497687221544,
      "grad_norm": 0.4120078682899475,
      "learning_rate": 0.00012587968217934168,
      "loss": 0.3377,
      "step": 660
    },
    {
      "epoch": 0.03802605068248248,
      "grad_norm": 0.38918182253837585,
      "learning_rate": 0.00012474460839954598,
      "loss": 0.3565,
      "step": 670
    },
    {
      "epoch": 0.03859360367774341,
      "grad_norm": 0.40390610694885254,
      "learning_rate": 0.0001236095346197503,
      "loss": 0.2535,
      "step": 680
    },
    {
      "epoch": 0.03916115667300434,
      "grad_norm": 0.47035372257232666,
      "learning_rate": 0.0001224744608399546,
      "loss": 0.3861,
      "step": 690
    },
    {
      "epoch": 0.03972870966826528,
      "grad_norm": 0.49428409337997437,
      "learning_rate": 0.00012133938706015893,
      "loss": 0.3646,
      "step": 700
    },
    {
      "epoch": 0.040296262663526206,
      "grad_norm": 0.4839082360267639,
      "learning_rate": 0.00012020431328036323,
      "loss": 0.4105,
      "step": 710
    },
    {
      "epoch": 0.04086381565878714,
      "grad_norm": 0.4317376911640167,
      "learning_rate": 0.00011906923950056754,
      "loss": 0.286,
      "step": 720
    },
    {
      "epoch": 0.04143136865404807,
      "grad_norm": 0.4755878448486328,
      "learning_rate": 0.00011793416572077185,
      "loss": 0.3936,
      "step": 730
    },
    {
      "epoch": 0.041998921649309004,
      "grad_norm": 0.41807594895362854,
      "learning_rate": 0.00011679909194097619,
      "loss": 0.4325,
      "step": 740
    },
    {
      "epoch": 0.04256647464456994,
      "grad_norm": 0.34396499395370483,
      "learning_rate": 0.00011566401816118048,
      "loss": 0.4045,
      "step": 750
    },
    {
      "epoch": 0.04313402763983087,
      "grad_norm": 0.306709885597229,
      "learning_rate": 0.00011452894438138479,
      "loss": 0.3764,
      "step": 760
    },
    {
      "epoch": 0.0437015806350918,
      "grad_norm": 0.33843910694122314,
      "learning_rate": 0.0001133938706015891,
      "loss": 0.3372,
      "step": 770
    },
    {
      "epoch": 0.04426913363035274,
      "grad_norm": 0.5561599135398865,
      "learning_rate": 0.00011225879682179344,
      "loss": 0.402,
      "step": 780
    },
    {
      "epoch": 0.044836686625613666,
      "grad_norm": 0.4310690462589264,
      "learning_rate": 0.00011112372304199773,
      "loss": 0.3443,
      "step": 790
    },
    {
      "epoch": 0.0454042396208746,
      "grad_norm": 0.4966055750846863,
      "learning_rate": 0.00010998864926220204,
      "loss": 0.3898,
      "step": 800
    },
    {
      "epoch": 0.04597179261613553,
      "grad_norm": 0.4822629690170288,
      "learning_rate": 0.00010885357548240635,
      "loss": 0.3593,
      "step": 810
    },
    {
      "epoch": 0.046539345611396464,
      "grad_norm": 0.44657373428344727,
      "learning_rate": 0.00010771850170261069,
      "loss": 0.4298,
      "step": 820
    },
    {
      "epoch": 0.0471068986066574,
      "grad_norm": 0.4889266788959503,
      "learning_rate": 0.000106583427922815,
      "loss": 0.3809,
      "step": 830
    },
    {
      "epoch": 0.04767445160191833,
      "grad_norm": 0.39174047112464905,
      "learning_rate": 0.0001054483541430193,
      "loss": 0.3766,
      "step": 840
    },
    {
      "epoch": 0.04824200459717926,
      "grad_norm": 0.3177376389503479,
      "learning_rate": 0.0001043132803632236,
      "loss": 0.4381,
      "step": 850
    },
    {
      "epoch": 0.0488095575924402,
      "grad_norm": 0.4305349886417389,
      "learning_rate": 0.00010317820658342794,
      "loss": 0.3708,
      "step": 860
    },
    {
      "epoch": 0.049377110587701126,
      "grad_norm": 0.4483747184276581,
      "learning_rate": 0.00010204313280363225,
      "loss": 0.3391,
      "step": 870
    },
    {
      "epoch": 0.04994466358296206,
      "grad_norm": 0.3486005663871765,
      "learning_rate": 0.00010090805902383655,
      "loss": 0.3436,
      "step": 880
    },
    {
      "epoch": 0.05051221657822299,
      "grad_norm": 0.40682846307754517,
      "learning_rate": 9.977298524404086e-05,
      "loss": 0.3488,
      "step": 890
    },
    {
      "epoch": 0.051079769573483924,
      "grad_norm": 0.4594676196575165,
      "learning_rate": 9.863791146424518e-05,
      "loss": 0.3463,
      "step": 900
    },
    {
      "epoch": 0.05164732256874486,
      "grad_norm": 0.36475661396980286,
      "learning_rate": 9.750283768444949e-05,
      "loss": 0.3333,
      "step": 910
    },
    {
      "epoch": 0.05221487556400579,
      "grad_norm": 0.4233013391494751,
      "learning_rate": 9.63677639046538e-05,
      "loss": 0.3514,
      "step": 920
    },
    {
      "epoch": 0.05278242855926672,
      "grad_norm": 0.4623965322971344,
      "learning_rate": 9.523269012485811e-05,
      "loss": 0.3821,
      "step": 930
    },
    {
      "epoch": 0.05334998155452765,
      "grad_norm": 0.5598728060722351,
      "learning_rate": 9.409761634506243e-05,
      "loss": 0.3512,
      "step": 940
    },
    {
      "epoch": 0.053917534549788586,
      "grad_norm": 0.39946413040161133,
      "learning_rate": 9.296254256526674e-05,
      "loss": 0.3208,
      "step": 950
    },
    {
      "epoch": 0.05448508754504952,
      "grad_norm": 0.33454662561416626,
      "learning_rate": 9.182746878547105e-05,
      "loss": 0.3574,
      "step": 960
    },
    {
      "epoch": 0.05505264054031045,
      "grad_norm": 0.4038584530353546,
      "learning_rate": 9.069239500567536e-05,
      "loss": 0.3898,
      "step": 970
    },
    {
      "epoch": 0.055620193535571384,
      "grad_norm": 0.4299520254135132,
      "learning_rate": 8.955732122587969e-05,
      "loss": 0.364,
      "step": 980
    },
    {
      "epoch": 0.05618774653083232,
      "grad_norm": 0.356835275888443,
      "learning_rate": 8.8422247446084e-05,
      "loss": 0.271,
      "step": 990
    },
    {
      "epoch": 0.05675529952609325,
      "grad_norm": 0.602198600769043,
      "learning_rate": 8.728717366628832e-05,
      "loss": 0.4871,
      "step": 1000
    },
    {
      "epoch": 0.05732285252135418,
      "grad_norm": 0.48748770356178284,
      "learning_rate": 8.615209988649262e-05,
      "loss": 0.3255,
      "step": 1010
    },
    {
      "epoch": 0.05789040551661511,
      "grad_norm": 0.4381444752216339,
      "learning_rate": 8.501702610669694e-05,
      "loss": 0.4572,
      "step": 1020
    },
    {
      "epoch": 0.058457958511876046,
      "grad_norm": 0.4103597104549408,
      "learning_rate": 8.388195232690125e-05,
      "loss": 0.3625,
      "step": 1030
    },
    {
      "epoch": 0.05902551150713698,
      "grad_norm": 0.5140973925590515,
      "learning_rate": 8.274687854710557e-05,
      "loss": 0.4469,
      "step": 1040
    },
    {
      "epoch": 0.05959306450239791,
      "grad_norm": 0.6941408514976501,
      "learning_rate": 8.161180476730987e-05,
      "loss": 0.4061,
      "step": 1050
    },
    {
      "epoch": 0.060160617497658844,
      "grad_norm": 0.30498334765434265,
      "learning_rate": 8.047673098751419e-05,
      "loss": 0.3904,
      "step": 1060
    },
    {
      "epoch": 0.06072817049291978,
      "grad_norm": 0.3824458122253418,
      "learning_rate": 7.93416572077185e-05,
      "loss": 0.4985,
      "step": 1070
    },
    {
      "epoch": 0.06129572348818071,
      "grad_norm": 0.32498279213905334,
      "learning_rate": 7.820658342792282e-05,
      "loss": 0.3663,
      "step": 1080
    },
    {
      "epoch": 0.06186327648344164,
      "grad_norm": 0.35860374569892883,
      "learning_rate": 7.707150964812712e-05,
      "loss": 0.3408,
      "step": 1090
    },
    {
      "epoch": 0.06243082947870257,
      "grad_norm": 0.3940589129924774,
      "learning_rate": 7.593643586833144e-05,
      "loss": 0.3956,
      "step": 1100
    },
    {
      "epoch": 0.06299838247396351,
      "grad_norm": 0.7586450576782227,
      "learning_rate": 7.480136208853575e-05,
      "loss": 0.4043,
      "step": 1110
    },
    {
      "epoch": 0.06356593546922444,
      "grad_norm": 0.37846946716308594,
      "learning_rate": 7.366628830874008e-05,
      "loss": 0.4864,
      "step": 1120
    },
    {
      "epoch": 0.06413348846448537,
      "grad_norm": 0.33092889189720154,
      "learning_rate": 7.253121452894437e-05,
      "loss": 0.3228,
      "step": 1130
    },
    {
      "epoch": 0.0647010414597463,
      "grad_norm": 0.38898664712905884,
      "learning_rate": 7.13961407491487e-05,
      "loss": 0.3797,
      "step": 1140
    },
    {
      "epoch": 0.06526859445500724,
      "grad_norm": 0.5221701264381409,
      "learning_rate": 7.0261066969353e-05,
      "loss": 0.3992,
      "step": 1150
    },
    {
      "epoch": 0.06583614745026817,
      "grad_norm": 0.6845812201499939,
      "learning_rate": 6.912599318955733e-05,
      "loss": 0.3874,
      "step": 1160
    },
    {
      "epoch": 0.0664037004455291,
      "grad_norm": 0.40334033966064453,
      "learning_rate": 6.799091940976164e-05,
      "loss": 0.3772,
      "step": 1170
    },
    {
      "epoch": 0.06697125344079004,
      "grad_norm": 0.42715364694595337,
      "learning_rate": 6.685584562996595e-05,
      "loss": 0.4152,
      "step": 1180
    },
    {
      "epoch": 0.06753880643605097,
      "grad_norm": 0.3091903626918793,
      "learning_rate": 6.572077185017026e-05,
      "loss": 0.3547,
      "step": 1190
    },
    {
      "epoch": 0.0681063594313119,
      "grad_norm": 0.44625523686408997,
      "learning_rate": 6.458569807037458e-05,
      "loss": 0.4111,
      "step": 1200
    },
    {
      "epoch": 0.06867391242657284,
      "grad_norm": 0.37732169032096863,
      "learning_rate": 6.345062429057889e-05,
      "loss": 0.3922,
      "step": 1210
    },
    {
      "epoch": 0.06924146542183376,
      "grad_norm": 0.42913806438446045,
      "learning_rate": 6.23155505107832e-05,
      "loss": 0.3448,
      "step": 1220
    },
    {
      "epoch": 0.06980901841709469,
      "grad_norm": 0.4115712344646454,
      "learning_rate": 6.118047673098751e-05,
      "loss": 0.3145,
      "step": 1230
    },
    {
      "epoch": 0.07037657141235563,
      "grad_norm": 0.4925505816936493,
      "learning_rate": 6.0045402951191835e-05,
      "loss": 0.3321,
      "step": 1240
    },
    {
      "epoch": 0.07094412440761656,
      "grad_norm": 0.3223428428173065,
      "learning_rate": 5.891032917139614e-05,
      "loss": 0.3441,
      "step": 1250
    },
    {
      "epoch": 0.07151167740287749,
      "grad_norm": 0.49873068928718567,
      "learning_rate": 5.777525539160046e-05,
      "loss": 0.3955,
      "step": 1260
    },
    {
      "epoch": 0.07207923039813843,
      "grad_norm": 0.2645813226699829,
      "learning_rate": 5.6640181611804764e-05,
      "loss": 0.2366,
      "step": 1270
    },
    {
      "epoch": 0.07264678339339936,
      "grad_norm": 0.39084577560424805,
      "learning_rate": 5.550510783200909e-05,
      "loss": 0.2982,
      "step": 1280
    },
    {
      "epoch": 0.07321433638866029,
      "grad_norm": 0.5057200789451599,
      "learning_rate": 5.437003405221339e-05,
      "loss": 0.3677,
      "step": 1290
    },
    {
      "epoch": 0.07378188938392122,
      "grad_norm": 0.5429602265357971,
      "learning_rate": 5.3234960272417714e-05,
      "loss": 0.3663,
      "step": 1300
    },
    {
      "epoch": 0.07434944237918216,
      "grad_norm": 0.4075734615325928,
      "learning_rate": 5.2099886492622017e-05,
      "loss": 0.3376,
      "step": 1310
    },
    {
      "epoch": 0.07491699537444309,
      "grad_norm": 0.4462432563304901,
      "learning_rate": 5.096481271282634e-05,
      "loss": 0.3702,
      "step": 1320
    },
    {
      "epoch": 0.07548454836970402,
      "grad_norm": 0.4051864743232727,
      "learning_rate": 4.982973893303065e-05,
      "loss": 0.3471,
      "step": 1330
    },
    {
      "epoch": 0.07605210136496496,
      "grad_norm": 0.5894443988800049,
      "learning_rate": 4.8694665153234966e-05,
      "loss": 0.4033,
      "step": 1340
    },
    {
      "epoch": 0.07661965436022589,
      "grad_norm": 0.37040042877197266,
      "learning_rate": 4.7559591373439276e-05,
      "loss": 0.364,
      "step": 1350
    },
    {
      "epoch": 0.07718720735548681,
      "grad_norm": 0.3145497739315033,
      "learning_rate": 4.642451759364359e-05,
      "loss": 0.353,
      "step": 1360
    },
    {
      "epoch": 0.07775476035074776,
      "grad_norm": 0.40984997153282166,
      "learning_rate": 4.52894438138479e-05,
      "loss": 0.3187,
      "step": 1370
    },
    {
      "epoch": 0.07832231334600868,
      "grad_norm": 0.33035367727279663,
      "learning_rate": 4.415437003405222e-05,
      "loss": 0.3174,
      "step": 1380
    },
    {
      "epoch": 0.07888986634126961,
      "grad_norm": 0.5133203864097595,
      "learning_rate": 4.301929625425653e-05,
      "loss": 0.4238,
      "step": 1390
    },
    {
      "epoch": 0.07945741933653055,
      "grad_norm": 0.5420546531677246,
      "learning_rate": 4.1884222474460845e-05,
      "loss": 0.3205,
      "step": 1400
    },
    {
      "epoch": 0.08002497233179148,
      "grad_norm": 0.3343038856983185,
      "learning_rate": 4.0749148694665155e-05,
      "loss": 0.3338,
      "step": 1410
    },
    {
      "epoch": 0.08059252532705241,
      "grad_norm": 0.34887102246284485,
      "learning_rate": 3.961407491486947e-05,
      "loss": 0.3942,
      "step": 1420
    },
    {
      "epoch": 0.08116007832231334,
      "grad_norm": 0.34754258394241333,
      "learning_rate": 3.847900113507378e-05,
      "loss": 0.3105,
      "step": 1430
    },
    {
      "epoch": 0.08172763131757428,
      "grad_norm": 0.5027568340301514,
      "learning_rate": 3.73439273552781e-05,
      "loss": 0.3438,
      "step": 1440
    },
    {
      "epoch": 0.08229518431283521,
      "grad_norm": 0.4696969985961914,
      "learning_rate": 3.620885357548241e-05,
      "loss": 0.3868,
      "step": 1450
    },
    {
      "epoch": 0.08286273730809614,
      "grad_norm": 0.44274893403053284,
      "learning_rate": 3.5073779795686724e-05,
      "loss": 0.3939,
      "step": 1460
    },
    {
      "epoch": 0.08343029030335708,
      "grad_norm": 0.30691102147102356,
      "learning_rate": 3.393870601589103e-05,
      "loss": 0.4075,
      "step": 1470
    },
    {
      "epoch": 0.08399784329861801,
      "grad_norm": 0.4378332793712616,
      "learning_rate": 3.280363223609535e-05,
      "loss": 0.3402,
      "step": 1480
    },
    {
      "epoch": 0.08456539629387894,
      "grad_norm": 0.49055665731430054,
      "learning_rate": 3.1668558456299666e-05,
      "loss": 0.4459,
      "step": 1490
    },
    {
      "epoch": 0.08513294928913988,
      "grad_norm": 0.28700047731399536,
      "learning_rate": 3.0533484676503976e-05,
      "loss": 0.3577,
      "step": 1500
    },
    {
      "epoch": 0.0857005022844008,
      "grad_norm": 0.5912836790084839,
      "learning_rate": 2.939841089670829e-05,
      "loss": 0.3969,
      "step": 1510
    },
    {
      "epoch": 0.08626805527966173,
      "grad_norm": 0.6356812715530396,
      "learning_rate": 2.8263337116912602e-05,
      "loss": 0.4453,
      "step": 1520
    },
    {
      "epoch": 0.08683560827492268,
      "grad_norm": 0.3459741771221161,
      "learning_rate": 2.7128263337116915e-05,
      "loss": 0.3505,
      "step": 1530
    },
    {
      "epoch": 0.0874031612701836,
      "grad_norm": 0.36309826374053955,
      "learning_rate": 2.599318955732123e-05,
      "loss": 0.3552,
      "step": 1540
    },
    {
      "epoch": 0.08797071426544453,
      "grad_norm": 0.41192832589149475,
      "learning_rate": 2.4858115777525538e-05,
      "loss": 0.3607,
      "step": 1550
    },
    {
      "epoch": 0.08853826726070547,
      "grad_norm": 0.4684116542339325,
      "learning_rate": 2.372304199772985e-05,
      "loss": 0.3643,
      "step": 1560
    },
    {
      "epoch": 0.0891058202559664,
      "grad_norm": 0.3007381558418274,
      "learning_rate": 2.2587968217934168e-05,
      "loss": 0.3518,
      "step": 1570
    },
    {
      "epoch": 0.08967337325122733,
      "grad_norm": 0.31894323229789734,
      "learning_rate": 2.145289443813848e-05,
      "loss": 0.3934,
      "step": 1580
    },
    {
      "epoch": 0.09024092624648826,
      "grad_norm": 0.4849683940410614,
      "learning_rate": 2.0317820658342794e-05,
      "loss": 0.4159,
      "step": 1590
    },
    {
      "epoch": 0.0908084792417492,
      "grad_norm": 0.5074499845504761,
      "learning_rate": 1.9182746878547107e-05,
      "loss": 0.35,
      "step": 1600
    },
    {
      "epoch": 0.09137603223701013,
      "grad_norm": 0.4521920382976532,
      "learning_rate": 1.804767309875142e-05,
      "loss": 0.3915,
      "step": 1610
    },
    {
      "epoch": 0.09194358523227106,
      "grad_norm": 0.4138904809951782,
      "learning_rate": 1.6912599318955733e-05,
      "loss": 0.3987,
      "step": 1620
    },
    {
      "epoch": 0.092511138227532,
      "grad_norm": 0.574067234992981,
      "learning_rate": 1.5777525539160047e-05,
      "loss": 0.3347,
      "step": 1630
    },
    {
      "epoch": 0.09307869122279293,
      "grad_norm": 0.432353675365448,
      "learning_rate": 1.464245175936436e-05,
      "loss": 0.4331,
      "step": 1640
    },
    {
      "epoch": 0.09364624421805386,
      "grad_norm": 0.5189046859741211,
      "learning_rate": 1.3507377979568673e-05,
      "loss": 0.3388,
      "step": 1650
    },
    {
      "epoch": 0.0942137972133148,
      "grad_norm": 0.3168368637561798,
      "learning_rate": 1.2372304199772986e-05,
      "loss": 0.4027,
      "step": 1660
    },
    {
      "epoch": 0.09478135020857573,
      "grad_norm": 0.5099204778671265,
      "learning_rate": 1.1237230419977299e-05,
      "loss": 0.3849,
      "step": 1670
    },
    {
      "epoch": 0.09534890320383665,
      "grad_norm": 0.3250751495361328,
      "learning_rate": 1.0102156640181612e-05,
      "loss": 0.3157,
      "step": 1680
    },
    {
      "epoch": 0.0959164561990976,
      "grad_norm": 0.4305640459060669,
      "learning_rate": 8.967082860385925e-06,
      "loss": 0.4599,
      "step": 1690
    },
    {
      "epoch": 0.09648400919435852,
      "grad_norm": 0.5239756107330322,
      "learning_rate": 7.832009080590238e-06,
      "loss": 0.3436,
      "step": 1700
    },
    {
      "epoch": 0.09705156218961945,
      "grad_norm": 0.37745165824890137,
      "learning_rate": 6.6969353007945516e-06,
      "loss": 0.381,
      "step": 1710
    },
    {
      "epoch": 0.0976191151848804,
      "grad_norm": 0.47847995162010193,
      "learning_rate": 5.561861520998865e-06,
      "loss": 0.466,
      "step": 1720
    },
    {
      "epoch": 0.09818666818014132,
      "grad_norm": 0.2896350920200348,
      "learning_rate": 4.426787741203179e-06,
      "loss": 0.3253,
      "step": 1730
    },
    {
      "epoch": 0.09875422117540225,
      "grad_norm": 0.496406614780426,
      "learning_rate": 3.2917139614074914e-06,
      "loss": 0.3752,
      "step": 1740
    },
    {
      "epoch": 0.09932177417066318,
      "grad_norm": 0.36169835925102234,
      "learning_rate": 2.156640181611805e-06,
      "loss": 0.308,
      "step": 1750
    },
    {
      "epoch": 0.09988932716592412,
      "grad_norm": 0.401045560836792,
      "learning_rate": 1.021566401816118e-06,
      "loss": 0.3722,
      "step": 1760
    }
  ],
  "logging_steps": 10,
  "max_steps": 1762,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.2423087563669504e+16,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}

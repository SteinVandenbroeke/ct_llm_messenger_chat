{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.010003263476027641,
  "eval_steps": 500,
  "global_step": 705,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.00014189026207131404,
      "grad_norm": 35.92058563232422,
      "learning_rate": 0.0001991489361702128,
      "loss": 13.268,
      "step": 10
    },
    {
      "epoch": 0.0002837805241426281,
      "grad_norm": 33.70838165283203,
      "learning_rate": 0.00019659574468085107,
      "loss": 6.018,
      "step": 20
    },
    {
      "epoch": 0.00042567078621394216,
      "grad_norm": 1.649326205253601,
      "learning_rate": 0.00019404255319148937,
      "loss": 1.6902,
      "step": 30
    },
    {
      "epoch": 0.0005675610482852562,
      "grad_norm": 1.3748503923416138,
      "learning_rate": 0.00019120567375886528,
      "loss": 0.7365,
      "step": 40
    },
    {
      "epoch": 0.0007094513103565702,
      "grad_norm": 0.7314656972885132,
      "learning_rate": 0.00018836879432624116,
      "loss": 0.5229,
      "step": 50
    },
    {
      "epoch": 0.0008513415724278843,
      "grad_norm": 1.3052310943603516,
      "learning_rate": 0.00018553191489361704,
      "loss": 0.5811,
      "step": 60
    },
    {
      "epoch": 0.0009932318344991983,
      "grad_norm": 1.3459771871566772,
      "learning_rate": 0.00018269503546099292,
      "loss": 0.6213,
      "step": 70
    },
    {
      "epoch": 0.0011351220965705123,
      "grad_norm": 1.0704278945922852,
      "learning_rate": 0.0001798581560283688,
      "loss": 0.5268,
      "step": 80
    },
    {
      "epoch": 0.0012770123586418264,
      "grad_norm": 1.0608525276184082,
      "learning_rate": 0.00017702127659574468,
      "loss": 0.4204,
      "step": 90
    },
    {
      "epoch": 0.0014189026207131405,
      "grad_norm": 0.6759021282196045,
      "learning_rate": 0.00017418439716312059,
      "loss": 0.47,
      "step": 100
    },
    {
      "epoch": 0.0015607928827844546,
      "grad_norm": 1.1215100288391113,
      "learning_rate": 0.00017134751773049647,
      "loss": 0.3941,
      "step": 110
    },
    {
      "epoch": 0.0017026831448557686,
      "grad_norm": 0.9837356805801392,
      "learning_rate": 0.00016851063829787235,
      "loss": 0.5281,
      "step": 120
    },
    {
      "epoch": 0.0018445734069270827,
      "grad_norm": 1.0328538417816162,
      "learning_rate": 0.00016567375886524823,
      "loss": 0.6269,
      "step": 130
    },
    {
      "epoch": 0.0019864636689983966,
      "grad_norm": 1.0418603420257568,
      "learning_rate": 0.0001628368794326241,
      "loss": 0.4977,
      "step": 140
    },
    {
      "epoch": 0.002128353931069711,
      "grad_norm": 1.3212065696716309,
      "learning_rate": 0.00016,
      "loss": 0.5137,
      "step": 150
    },
    {
      "epoch": 0.0022702441931410247,
      "grad_norm": 1.1119036674499512,
      "learning_rate": 0.0001571631205673759,
      "loss": 0.3259,
      "step": 160
    },
    {
      "epoch": 0.002412134455212339,
      "grad_norm": 0.8047376275062561,
      "learning_rate": 0.00015432624113475177,
      "loss": 0.4952,
      "step": 170
    },
    {
      "epoch": 0.002554024717283653,
      "grad_norm": 0.9456294178962708,
      "learning_rate": 0.00015148936170212765,
      "loss": 0.4643,
      "step": 180
    },
    {
      "epoch": 0.0026959149793549667,
      "grad_norm": 0.8913679718971252,
      "learning_rate": 0.00014865248226950353,
      "loss": 0.5027,
      "step": 190
    },
    {
      "epoch": 0.002837805241426281,
      "grad_norm": 1.2338390350341797,
      "learning_rate": 0.00014581560283687944,
      "loss": 0.2764,
      "step": 200
    },
    {
      "epoch": 0.002979695503497595,
      "grad_norm": 0.5497622489929199,
      "learning_rate": 0.00014297872340425532,
      "loss": 0.5074,
      "step": 210
    },
    {
      "epoch": 0.003121585765568909,
      "grad_norm": 0.5425580739974976,
      "learning_rate": 0.00014014184397163123,
      "loss": 0.3538,
      "step": 220
    },
    {
      "epoch": 0.003263476027640223,
      "grad_norm": 0.6034130454063416,
      "learning_rate": 0.0001373049645390071,
      "loss": 0.3008,
      "step": 230
    },
    {
      "epoch": 0.0034053662897115373,
      "grad_norm": 0.41267284750938416,
      "learning_rate": 0.000134468085106383,
      "loss": 0.3219,
      "step": 240
    },
    {
      "epoch": 0.003547256551782851,
      "grad_norm": 0.583770751953125,
      "learning_rate": 0.00013163120567375887,
      "loss": 0.5055,
      "step": 250
    },
    {
      "epoch": 0.0036891468138541654,
      "grad_norm": 0.7361137866973877,
      "learning_rate": 0.00012879432624113477,
      "loss": 0.3286,
      "step": 260
    },
    {
      "epoch": 0.0038310370759254793,
      "grad_norm": 0.5994325876235962,
      "learning_rate": 0.00012595744680851065,
      "loss": 0.4411,
      "step": 270
    },
    {
      "epoch": 0.003972927337996793,
      "grad_norm": 0.7444449663162231,
      "learning_rate": 0.00012312056737588653,
      "loss": 0.4076,
      "step": 280
    },
    {
      "epoch": 0.004114817600068107,
      "grad_norm": 0.740185558795929,
      "learning_rate": 0.00012028368794326242,
      "loss": 0.3789,
      "step": 290
    },
    {
      "epoch": 0.004256707862139422,
      "grad_norm": 0.8835834860801697,
      "learning_rate": 0.0001174468085106383,
      "loss": 0.4605,
      "step": 300
    },
    {
      "epoch": 0.0043985981242107355,
      "grad_norm": 1.5823211669921875,
      "learning_rate": 0.0001146099290780142,
      "loss": 0.6144,
      "step": 310
    },
    {
      "epoch": 0.004540488386282049,
      "grad_norm": 1.3398301601409912,
      "learning_rate": 0.00011177304964539008,
      "loss": 0.4103,
      "step": 320
    },
    {
      "epoch": 0.004682378648353363,
      "grad_norm": 0.8243424296379089,
      "learning_rate": 0.00010893617021276596,
      "loss": 0.3327,
      "step": 330
    },
    {
      "epoch": 0.004824268910424678,
      "grad_norm": 0.5508114099502563,
      "learning_rate": 0.00010609929078014184,
      "loss": 0.3685,
      "step": 340
    },
    {
      "epoch": 0.004966159172495992,
      "grad_norm": 0.7948297262191772,
      "learning_rate": 0.00010326241134751772,
      "loss": 0.4083,
      "step": 350
    },
    {
      "epoch": 0.005108049434567306,
      "grad_norm": 0.4856223464012146,
      "learning_rate": 0.00010042553191489362,
      "loss": 0.4477,
      "step": 360
    },
    {
      "epoch": 0.0052499396966386195,
      "grad_norm": 0.8623353838920593,
      "learning_rate": 9.758865248226951e-05,
      "loss": 0.3694,
      "step": 370
    },
    {
      "epoch": 0.005391829958709933,
      "grad_norm": 0.43400052189826965,
      "learning_rate": 9.47517730496454e-05,
      "loss": 0.3981,
      "step": 380
    },
    {
      "epoch": 0.005533720220781248,
      "grad_norm": 1.0696344375610352,
      "learning_rate": 9.191489361702128e-05,
      "loss": 0.5998,
      "step": 390
    },
    {
      "epoch": 0.005675610482852562,
      "grad_norm": 1.1431536674499512,
      "learning_rate": 8.907801418439716e-05,
      "loss": 0.4257,
      "step": 400
    },
    {
      "epoch": 0.005817500744923876,
      "grad_norm": 0.5529459714889526,
      "learning_rate": 8.624113475177306e-05,
      "loss": 0.3161,
      "step": 410
    },
    {
      "epoch": 0.00595939100699519,
      "grad_norm": 1.3990750312805176,
      "learning_rate": 8.340425531914894e-05,
      "loss": 0.4762,
      "step": 420
    },
    {
      "epoch": 0.006101281269066504,
      "grad_norm": 0.9281232953071594,
      "learning_rate": 8.056737588652483e-05,
      "loss": 0.35,
      "step": 430
    },
    {
      "epoch": 0.006243171531137818,
      "grad_norm": 0.5114339590072632,
      "learning_rate": 7.773049645390071e-05,
      "loss": 0.2958,
      "step": 440
    },
    {
      "epoch": 0.006385061793209132,
      "grad_norm": 0.5045478940010071,
      "learning_rate": 7.489361702127659e-05,
      "loss": 0.4533,
      "step": 450
    },
    {
      "epoch": 0.006526952055280446,
      "grad_norm": 1.7004544734954834,
      "learning_rate": 7.205673758865248e-05,
      "loss": 0.5956,
      "step": 460
    },
    {
      "epoch": 0.00666884231735176,
      "grad_norm": 0.4482499361038208,
      "learning_rate": 6.921985815602838e-05,
      "loss": 0.4187,
      "step": 470
    },
    {
      "epoch": 0.0068107325794230745,
      "grad_norm": 1.393815517425537,
      "learning_rate": 6.638297872340426e-05,
      "loss": 0.5231,
      "step": 480
    },
    {
      "epoch": 0.006952622841494388,
      "grad_norm": 0.5983469486236572,
      "learning_rate": 6.354609929078015e-05,
      "loss": 0.502,
      "step": 490
    },
    {
      "epoch": 0.007094513103565702,
      "grad_norm": 0.8380671739578247,
      "learning_rate": 6.070921985815603e-05,
      "loss": 0.3532,
      "step": 500
    },
    {
      "epoch": 0.007236403365637016,
      "grad_norm": 0.48774582147598267,
      "learning_rate": 5.787234042553191e-05,
      "loss": 0.4336,
      "step": 510
    },
    {
      "epoch": 0.007378293627708331,
      "grad_norm": 0.766282856464386,
      "learning_rate": 5.5035460992907805e-05,
      "loss": 0.3721,
      "step": 520
    },
    {
      "epoch": 0.007520183889779645,
      "grad_norm": 0.7660230994224548,
      "learning_rate": 5.2198581560283685e-05,
      "loss": 0.5353,
      "step": 530
    },
    {
      "epoch": 0.0076620741518509585,
      "grad_norm": 1.7079490423202515,
      "learning_rate": 4.936170212765958e-05,
      "loss": 0.3266,
      "step": 540
    },
    {
      "epoch": 0.007803964413922272,
      "grad_norm": 0.7875921130180359,
      "learning_rate": 4.6524822695035466e-05,
      "loss": 0.4584,
      "step": 550
    },
    {
      "epoch": 0.007945854675993586,
      "grad_norm": 0.9641896486282349,
      "learning_rate": 4.368794326241135e-05,
      "loss": 0.4812,
      "step": 560
    },
    {
      "epoch": 0.008087744938064901,
      "grad_norm": 0.6296448111534119,
      "learning_rate": 4.085106382978723e-05,
      "loss": 0.3278,
      "step": 570
    },
    {
      "epoch": 0.008229635200136214,
      "grad_norm": 0.8354709148406982,
      "learning_rate": 3.801418439716312e-05,
      "loss": 0.3662,
      "step": 580
    },
    {
      "epoch": 0.008371525462207529,
      "grad_norm": 0.8249157071113586,
      "learning_rate": 3.517730496453901e-05,
      "loss": 0.4467,
      "step": 590
    },
    {
      "epoch": 0.008513415724278843,
      "grad_norm": 0.9233046770095825,
      "learning_rate": 3.23404255319149e-05,
      "loss": 0.3004,
      "step": 600
    },
    {
      "epoch": 0.008655305986350156,
      "grad_norm": 0.4121677875518799,
      "learning_rate": 2.950354609929078e-05,
      "loss": 0.3354,
      "step": 610
    },
    {
      "epoch": 0.008797196248421471,
      "grad_norm": 0.5831228494644165,
      "learning_rate": 2.6666666666666667e-05,
      "loss": 0.4536,
      "step": 620
    },
    {
      "epoch": 0.008939086510492784,
      "grad_norm": 1.0035841464996338,
      "learning_rate": 2.3829787234042557e-05,
      "loss": 0.4951,
      "step": 630
    },
    {
      "epoch": 0.009080976772564099,
      "grad_norm": 0.7691408395767212,
      "learning_rate": 2.099290780141844e-05,
      "loss": 0.3043,
      "step": 640
    },
    {
      "epoch": 0.009222867034635414,
      "grad_norm": 0.6875863075256348,
      "learning_rate": 1.8156028368794327e-05,
      "loss": 0.2705,
      "step": 650
    },
    {
      "epoch": 0.009364757296706726,
      "grad_norm": 0.8619449734687805,
      "learning_rate": 1.5319148936170214e-05,
      "loss": 0.4907,
      "step": 660
    },
    {
      "epoch": 0.009506647558778041,
      "grad_norm": 1.1510084867477417,
      "learning_rate": 1.24822695035461e-05,
      "loss": 0.479,
      "step": 670
    },
    {
      "epoch": 0.009648537820849356,
      "grad_norm": 0.8568385243415833,
      "learning_rate": 9.645390070921986e-06,
      "loss": 0.2947,
      "step": 680
    },
    {
      "epoch": 0.009790428082920669,
      "grad_norm": 1.286248803138733,
      "learning_rate": 6.808510638297873e-06,
      "loss": 0.4386,
      "step": 690
    },
    {
      "epoch": 0.009932318344991984,
      "grad_norm": 1.1125459671020508,
      "learning_rate": 3.9716312056737595e-06,
      "loss": 0.4083,
      "step": 700
    }
  ],
  "logging_steps": 10,
  "max_steps": 705,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2242945052835840.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
